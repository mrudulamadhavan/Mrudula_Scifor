{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhEo1Z3GU33tEVTZu+zYld",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrudulamadhavan/Mrudula_Scifor/blob/main/week%206/NLP%20Test%20Q%26A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NLP Test Questions & Answers**"
      ],
      "metadata": {
        "id": "jgSGholC8nRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What you understand by Text Processing? Write a code to perform text processing\n"
      ],
      "metadata": {
        "id": "lrs_Ixue8ovz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st3nYoXJ8JLZ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def text_processing(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Perform stemming\n",
        "    porter = PorterStemmer()\n",
        "    tokens = [porter.stem(token) for token in tokens]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Given text\n",
        "text = \"If you want to see a sunrise, Ken said, we can go hiking in the morning next time.\"\n",
        "\n",
        "# Process the text\n",
        "processed_text = text_processing(text)\n",
        "\n",
        "# Display the processed text\n",
        "print(\"Processed Text:\")\n",
        "print(processed_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. What you understand by NLP toolkit and spacy library? Write a code in which any one gets used.\n",
        "\n",
        "**Natural Language Processing (NLP) Toolkit**\n",
        "\n",
        "An NLP toolkit is a collection of libraries and tools designed to process and analyze natural language data. It typically includes functionalities for tokenization, part-of-speech tagging, named entity recognition, sentiment analysis, and more. NLTK (Natural Language Toolkit) is a popular Python library for NLP, offering a wide range of tools and resources for linguistic tasks.\n",
        "\n",
        "**spaCy Library**\n",
        "\n",
        "Spacy is an open-source Natural Language Processing library that can be used for various tasks. It has built-in methods for Named Entity Recognition. Spacy has a fast statistical entity recognition system.It is designed for production use and is known for its speed and ease of use. Spacy has a fast statistical entity recognition system.\n",
        "\n"
      ],
      "metadata": {
        "id": "KXhMb2-p87Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "NER = spacy.load(\"en_core_web_sm\")\n",
        "raw_text=\"The Indian Space Research Organisation or is the national space agency of India, headquartered in Bengaluru.Apple tops Indian smartphone market by revenue in 2023\"\n",
        "text1= NER(raw_text)\n",
        "for word in text1.ents:\n",
        "    print(word.text,\" : \",word.label_)\n",
        "\n",
        "displacy.render(text1,style=\"ent\",jupyter=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "tSNuOdCPDZDz",
        "outputId": "b1277b8b-e842-4030-8962-1c0ea61d7941"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Indian Space Research Organisation  :  ORG\n",
            "India  :  GPE\n",
            "Bengaluru  :  GPE\n",
            "Apple  :  ORG\n",
            "Indian  :  NORP\n",
            "2023  :  DATE\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    The Indian Space Research Organisation\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " or is the national space agency of \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    India\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", headquartered in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bengaluru\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ".\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " tops \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Indian\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " smartphone market by revenue in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2023\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Describe Neural Networks and Deep Learning in depth.\n",
        "\n",
        "### **Neural Networks**\n",
        "\n",
        "A Neural Network (NN) is a computational model inspired by the human brain's structure and functioning. It consists of interconnected nodes, or artificial neurons, organized into layers. The three main types of layers are the input layer, hidden layers, and output layer. Neurons in each layer are connected with weighted edges, and each connection has an associated weight that the network learns during training.\n",
        "\n",
        "* Feedforward Neural Networks (FNN): In FNN, information flows in one directionâ€”from the input layer through the hidden layers to the output layer. It is commonly used for tasks like image and speech recognition.\n",
        "\n",
        "* Recurrent Neural Networks (RNN): RNNs have connections that form directed cycles, allowing them to capture sequential dependencies. They are well-suited for tasks involving sequential data, such as time series analysis and natural language processing.\n",
        "\n",
        "* Convolutional Neural Networks (CNN): CNNs are designed for tasks involving grid-like data, such as images. They use convolutional layers to efficiently learn hierarchical representations of patterns.\n",
        "\n",
        "### **Deep Learning**\n",
        "\n",
        "Deep Learning (DL) is a subfield of machine learning that focuses on neural networks with many layers, often referred to as deep neural networks. Deep learning has gained prominence due to its ability to automatically learn hierarchical representations from data, enabling the extraction of complex features.\n",
        "\n",
        "* Deep Neural Networks (DNN):\n",
        "\n",
        "    A deep neural network typically has more than one hidden layer, allowing it to model intricate relationships in the data. It excels in tasks with large amounts of labeled data.\n",
        "\n",
        "* Training and Backpropagation:\n",
        "\n",
        "    Deep learning models are trained using optimization algorithms like gradient descent and backpropagation. Backpropagation adjusts the model's weights by minimizing the difference between predicted and actual outputs.\n",
        "\n",
        "* Activation Functions:\n",
        "\n",
        "    Non-linear activation functions (e.g., ReLU, Sigmoid, Tanh) introduce non-linearity to the model, enabling it to learn complex mappings between inputs and outputs.\n",
        "\n",
        "* Loss Functions:\n",
        "\n",
        "    Loss functions measure the difference between predicted and actual values. Common loss functions include Mean Squared Error (MSE) for regression tasks and Cross-Entropy for classification tasks.\n",
        "\n",
        "* Applications:\n",
        "\n",
        "    Deep learning has achieved remarkable success in various domains, including computer vision (object recognition), natural language processing (language translation, sentiment analysis), speech recognition, and reinforcement learning.\n",
        "\n",
        "**Challenges:**\n",
        "\n",
        "* Computational Resources: Deep learning models demand significant computational power for training, which can be resource-intensive.\n",
        "\n",
        "* Interpretability: As deep networks become more complex, interpreting their decision-making processes becomes challenging.\n",
        "\n",
        "* Data Requirements: Deep learning models often require large amounts of labeled data for effective training, which may be a limitation in some domains.\n",
        "\n",
        "In summary, neural networks form the foundation of deep learning, with deep neural networks exhibiting remarkable capabilities in learning complex representations from data, leading to state-of-the-art performance in various tasks.\n"
      ],
      "metadata": {
        "id": "TOl4-lwv8_oW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.What you understand by Hyperparameter Tuning?\n",
        "\n",
        "Hyperparameter tuning is a critical phase in machine learning, involving the adjustment of external configuration settings, or hyperparameters, to optimize model performance. Hyperparameters, distinct from internal parameters learned during training, significantly influence a model's behavior.\n",
        "\n",
        "* **Grid search** systematically explores predefined hyperparameter values within specified ranges, offering a comprehensive but computationally expensive approach.\n",
        "* **Random search** provides an efficient alternative by randomly sampling hyperparameter values, particularly useful for resource-constrained scenarios.\n",
        "* **Bayesian optimization** employs probabilistic models, intelligently guiding the search process and excelling with expensive-to-evaluate models."
      ],
      "metadata": {
        "id": "gW3uwx8t9ETM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. What you understand by Ensemble Learning?\n",
        "\n",
        "Ensemble Learning is a machine learning technique that involves combining the predictions of multiple individual models to create a stronger, more robust, and accurate model. The main idea is that by aggregating the predictions of several models, the ensemble can often outperform any individual model within the ensemble. This approach is particularly beneficial when dealing with complex datasets and diverse patterns that might not be captured effectively by a single model.\n",
        "\n",
        "The predictions from individual models are combined through various techniques, such as averaging, voting, or weighted averaging.The ensemble prediction often outperforms the predictions of its individual components, resulting in a more reliable and accurate model.\n",
        "\n",
        "**Common Ensemble Techniques:**\n",
        "* Bagging (Bootstrap Aggregating)\n",
        "\n",
        "> * Train multiple instances of the same model on different subsets of the training data (selected with replacement).\n",
        "> * Example: Random Forests, which are an ensemble of decision trees trained on different bootstrap samples of the data.\n",
        "\n",
        "* Boosting\n",
        "\n",
        "> * Train multiple weak learners sequentially, with each learner focusing on correcting the errors of its predecessor.\n",
        "> * Example: AdaBoost (Adaptive Boosting) and Gradient Boosting. These algorithms assign different weights to instances in the dataset, emphasizing the misclassified instances to improve overall performance.\n",
        "\n",
        "* Stacking\n",
        "\n",
        "> * Combine predictions from multiple models using another model (meta-model) that takes these predictions as input.\n",
        "> * Example: Train multiple diverse models, obtain their predictions, and use these predictions as features to train a meta-model.\n",
        "\n",
        "**Advantages of Ensemble Learning:**\n",
        "* Improved Accuracy: Ensemble methods often lead to higher accuracy than individual models, especially when models are diverse.\n",
        "\n",
        "* Robustness: Ensembles are less susceptible to overfitting on specific patterns in the training data.\n",
        "\n",
        "* Generalization: Ensemble methods generalize well to new, unseen data, making them suitable for a wide range of applications.\n",
        "\n",
        "* Handling Noise: Ensemble methods can be effective in handling noisy data and outliers.\n",
        "\n",
        "**Considerations:**\n",
        "* Computational Cost: Training multiple models can be computationally expensive, especially for large datasets.\n",
        "\n",
        "* Interpretability: Ensembles might sacrifice interpretability, as understanding the reasoning behind the combined predictions can be complex.\n",
        "\n",
        "Ensemble Learning has proven to be a powerful tool in machine learning, and its applications extend to various domains, contributing to the success of models in predictive tasks."
      ],
      "metadata": {
        "id": "Cs743iy19HqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. What do you understand by Model Evaluation and Selection ?\n",
        "\n",
        "###**Model Evaluation**\n",
        "\n",
        "Model evaluation is the process of assessing the performance of a trained machine learning model. It involves comparing the model's predictions to the actual outcomes on a set of data reserved for evaluation, typically the test set.\n",
        "\n",
        "Goals:\n",
        "\n",
        "1) Performance Assessment: Understand how well the model generalizes to unseen data and performs on tasks it was trained for.\n",
        "\n",
        "2) Identify Weaknesses: Identify areas where the model may struggle, such as handling specific classes or making accurate predictions under certain conditions.\n",
        "\n",
        "3) Optimization: Use evaluation results to fine-tune hyperparameters, modify the model architecture, or adjust preprocessing steps.\n",
        "\n",
        "**Common Metrics:**\n",
        "\n",
        "* Accuracy: The proportion of correctly classified instances out of the total instances.\n",
        "* Precision: The ratio of correctly predicted positive observations to the total predicted positives (relevant in binary and multiclass classification).\n",
        "* Recall (Sensitivity or True Positive Rate): The ratio of correctly predicted positive observations to the all observations in actual class.\n",
        "* F1 Score: The harmonic mean of precision and recall, providing a balance between precision and recall.\n",
        "* Area Under the ROC Curve (AUC-ROC): Evaluates the trade-off between true positive rate and false positive rate.\n",
        "###**Model Selection**\n",
        "\n",
        "Model selection is the process of choosing the best-performing model among different candidate models. It involves training multiple models with different configurations or algorithms and selecting the one that performs the best on the evaluation metrics.\n",
        "\n",
        "Goals:\n",
        "\n",
        "1) Optimal Model Choice: Choose a model that strikes the right balance between bias and variance and generalizes well to new, unseen data.\n",
        "\n",
        "2) Avoid Overfitting: Ensure that the selected model doesn't overfit the training data and performs well on diverse datasets.\n",
        "\n",
        "3) Balancing Complexity: Consider the trade-off between model complexity and performance.\n",
        "\n",
        "Methods:\n",
        "\n",
        "* Cross-Validation: Split the dataset into multiple subsets, train the model on different subsets, and evaluate on the remaining data. This helps assess how well the model generalizes to different partitions of the data.\n",
        "* Grid Search: Systematically test different hyperparameter combinations to find the set that results in the best model performance.\n",
        "* Random Search: Similar to grid search, but instead of testing all possible combinations, random search tests a random subset of hyperparameter combinations.\n",
        "* Ensemble Methods: Combine predictions from multiple models (e.g., Random Forests or Gradient Boosting) to create a more robust and accurate model.\n",
        "\n",
        "**Key Difference:**\n",
        "\n",
        "* Model Evaluation: Focuses on assessing the performance of a specific model on a given dataset using various metrics.\n",
        "\n",
        "* Model Selection: Involves comparing and choosing the best-performing model among different models or configurations based on evaluation metrics.\n",
        "\n",
        "In practice, both model evaluation and model selection are iterative processes. Model evaluation helps understand the current model's strengths and weaknesses, while model selection helps choose the most suitable model for a particular task.\n"
      ],
      "metadata": {
        "id": "pPQUCZyA9Lqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. What you understand by Feature Engineering and Feature selection? What is the difference between them?**\n",
        "\n",
        "### **Feature Engineering**\n",
        "\n",
        "Feature engineering involves creating new features or modifying existing ones to enhance the dataset's quality and provide more informative input to machine learning models.\n",
        "\n",
        "Goals:\n",
        "\n",
        "* Improving Model Performance: By introducing new features or transforming existing ones, we aim to capture more relevant information that can potentially lead to better model performance.\n",
        "\n",
        "* Handling Complex Relationships: Creating interaction terms, polynomial features, or domain-specific transformations helps the model better capture complex relationships within the data.\n",
        "\n",
        "* Dealing with Non-Linearity: In scenarios where relationships between features and the target variable are non-linear, feature engineering can help linear models by creating new representations.\n",
        "\n",
        "Examples:\n",
        "\n",
        "* Interaction Terms: Combining two or more features to capture their joint effect. For instance, in a housing dataset, combining \"number of bedrooms\" and \"number of bathrooms\" to create a new feature representing the interaction between them.\n",
        "\n",
        "* Polynomial Features: Introducing polynomial terms, such as squaring or cubing existing features, to account for non-linear relationships.\n",
        "\n",
        "* Encoding Categorical Variables: Converting categorical variables into a numerical format that the model can understand, such as one-hot encoding or label encoding.\n",
        "\n",
        "* Temporal Features: Extracting features related to time, like day of the week, month, or season, which can be useful in time-series analysis.\n",
        "\n",
        "### **Feature Selection**\n",
        "\n",
        "Feature selection involves choosing a subset of relevant features from the original set to simplify models, reduce overfitting, and improve computational efficiency.\n",
        "\n",
        "Goals:\n",
        "\n",
        "* Simplifying Models: By selecting only the most relevant features, we aim to simplify the model's structure, making it more interpretable and easier to understand.\n",
        "\n",
        "* Reducing Overfitting: Including irrelevant features may lead to overfitting, where the model performs well on the training data but poorly on new, unseen data. Feature selection helps mitigate this issue.\n",
        "\n",
        "* Improving Computational Efficiency: Fewer features mean less computational resources required for training and making predictions, which is crucial for large datasets.\n",
        "\n",
        "Examples:\n",
        "\n",
        "* Univariate Feature Selection: Selecting features based on univariate statistical tests, such as chi-squared tests or mutual information.\n",
        "\n",
        "* Recursive Feature Elimination (RFE): Iteratively removing the least important features based on model performance until the desired number of features is reached.\n",
        "\n",
        "* Feature Importance from Models: Some models provide feature importance scores, and features can be selected based on these scores. Random Forests and Gradient Boosting models are examples.\n",
        "\n",
        "* Dimensionality Reduction: Techniques like Principal Component Analysis (PCA) reduce the dataset's dimensionality by transforming features into a new set of uncorrelated features.\n",
        "\n",
        "**Key Difference:**\n",
        "\n",
        "1) Creation vs. Selection: Feature engineering involves creating new features or transforming existing ones, while feature selection involves choosing a subset of features from the existing set.\n",
        "\n",
        "2) Information vs. Simplicity: Feature engineering aims to provide more information to the model, capturing complex relationships. Feature selection aims to simplify models by retaining only the most relevant features.\n",
        "\n",
        "In practice, a combination of both feature engineering and feature selection is often employed to achieve the best model performance while maintaining simplicity and interpretability. The choice between these techniques depends on the specific characteristics of the dataset and the goals of the machine learning task."
      ],
      "metadata": {
        "id": "P1SizNnD9PTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------------------------------------\n",
        "-----------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "h_6sR0Cd9ROR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submitted by : Mrudula A P**"
      ],
      "metadata": {
        "id": "l2iUji-e9Z58"
      }
    }
  ]
}